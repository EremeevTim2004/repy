Искусственный интеллект не является недавним открытием. 
 Она исходит из десятилетия 1950, но, 
 несмотря на эволюцию своей структуры,
 некоторые аспекты доверия не хватало.
 Одним из таких аспектов является объем данных,
 который возник в широком разнообразии и скорости,
 что позволяет создавать стандарты с высокой степенью точности. 
 Тем не менее, соответствующий момент был о том,
 как большие модели машинного обучения были обработаны с большими объемами информации,
 потому что компьютеры не могут выполнять такие действия. 

 В этот момент был идентифицирован второй аспект,
 который упоминается параллельно программированию на графических процессерах.
 Графические процессорные единицы,
 которые позволяют параллельно осуществлять математические операции, 
 особенно с матрицами и векторами,
 которые присутствуют в моделях искусственных сетей, 
 позволили нынешней эволюции,
 суммирование больших объемов данных (большой объем данных);
 Параллельная обработка и модели машинного обучения 
 представляют собой в результате искусственный интеллект. 

 Базовая единица искусственной нейронной сети — это математический нейрон, называемый также узлом, 
 основанный на биологическом нейроне. Связи между этими математическими нейронами связаны с биологическими мозгами,
 и особенно в том, как эти ассоциации развиваются с течением времени, называемых «обучением».

 В период между второй половиной десятилетия 80 и началом десятилетия 90,
 произошло несколько соответствующих достижений в структуре искусственных сетей. 
 Тем не менее, количество времени и информации, необходимой для достижения хороших результатов, 
 откладывал принятие, затрагивающих интерес к искусственному интеллекту.

 В начале 2000 годов, мощность вычислений расширилась и рынок испытал "бум" вычислительных технологий, которые не были возможны раньше. 
 Именно тогда, когда глубокое обучение возникло из-за большого вычислительного роста того времени, 
 как необходимый механизм для разработки систем искусственного интеллекта, выиграв несколько конкурсов машинного обучения.
 Интерес к глубокому обучению продолжает расти до сегодняшнего дня, и несколько коммерческих решений возникают во все времена.

 С течением времени, несколько исследований были созданы для того, чтобы имитировать функционирование мозга,
 особенно в процессе обучения для создания интеллектуальных систем, 
 которые могли бы воссоздать такие задачи, как классификация и распознавание образов, среди другие виды деятельности.
 Выводы этих исследований породили модель искусственного нейрона, размещенный позже в взаимосвязанной сети, называемой нейронной сетью.

 В 1943, Уоррен Маккалок, нейрофизиолог и Уолтер Питтс, математик, создал простую нейронную сеть, используя электрические схемы и
 разработал компьютерную модель для нейронных сетей на основе математических концепций и алгоритмов, 
 называемых пороговых логика или пороговая логика, 
 которая позволяла исследовать нейронную сеть, разделенную на две нити: фокусируясь на биологическом процессе мозга,
 а другой фокусируясь на применении этих нейронных сетей, направленных на искусственный интеллект. 

 Дональд Хебб, в 1949, написал произведение, где он сообщил, что нейронные цепи усилены больше они используются, 
 как сущность обучения. С развитием компьютеров в 1950 десятилетие, идея нейронной сети приобрел силу и Натаниэль Рочестер 
 из IBM в лабораториях исследования пытались составить один, но не удалось.

 Летний исследовательский проект Дартмута по искусственному интеллекту, в 1956,
 увеличил нейронные сети, а также искусственный интеллект,
 поощряя исследования в этой области по отношению к нейронной обработке. 
 В последующие годы Джон фон Нейман имитировал простые функции нейронов с вакуумными трубами или телеграфами,
 в то время как Фрэнк Розенблатт инициировал проект Перцептрон, анализируя функционирование глаза мухи.
 Результатом этого исследования стало оборудование,
 которое является старейшей нейронной сетью, используемой до настоящего времени.
 Однако Перцептрон очень ограничен, что доказали Марвин и Пейперт.

 % Рисунок 

 Несколько лет спустя, в 1959 году, Бернард Уидроу и Марциан Хофф
 разработали две модели под названием «Адалин» и «Мадалин». 
 Номенклатура вытекает из использования нескольких элементов: адаптивной линейной. 
 Адалин был создан для идентификации бинарных шаблонов,
 чтобы сделать прогнозы о следующем битом, 
 в то время как "Маделин" была первой нейронной сетью,
 прилотой к реальной проблеме, используя адаптивный фильтр.
 Система все еще используется, но только коммерческие.

 Достигнутый ранее прогресс привел к убеждению, 
 что потенциал нейронных сетей ограничен электроникой. 
 Он был задан вопрос о воздействии, 
 что "умные машины" будет иметь на человека и общества в целом.

 Дебаты о том, как искусственный интеллект повлияет на человека,
 вызвали критику по поводу исследований в нейронных сетях, 
 что привело к сокращению финансирования и, следовательно,
 исследования в области, которая оставалась до 1981.

 В следующем году, несколько событий ререакинтерес в этой области.
 Джон Хопфилд из Калифорнийского технологического института представил подход к созданию полезных устройств, 
 демонстрируя свои назначения. В 1985 году американский институт физики начал ежегодное совещание под названием нейронные сети для вычислений.
 В 1986, средства массовой информации начали сообщать о нейронных сетях нескольких слоев, и три исследователя представили похожие идеи, 
 называемые Backpropagation сетей, потому что они распространяют шаблоны идентификации сбоев по всей сети.

 Гибридные сети имеют только два слоя, в то время как сети обратного распространения представляют многие,
 так что эта сеть сохраняет информацию медленнее, потому что им нужно тысячи итераций, чтобы узнать,
 но и представить больше результатов Точная. Уже в 1987 году была первая международная конференция 
 по нейросетям института электротехнического иэлектронного инженера (IEEE).

 В 1989 году ученые создали алгоритмы, которые использовали глубокие нейронные сети,
 но время «обучения» было очень долгим, 
 что помешало его применению к реальности. 
 В 1992,Juyang Weng Diulga метод Кресскиртрон 
 для выполнения распознавания 3D объектов из бурных сцен. 

 В середине 2000 лет термин «глубокое обучение» или «глубокое обучение» 
 начинают распространяться после статьи Джеффри Хинтона и Руслана Салахатдинова,
 которые продемонстрировали, как многослойная нейронная сеть 
 может быть предварительно обучалась, один слой в то время, . 

 В 2009, нейронные сети системы обработки семинар по глубокому обучению для распознавания голоса происходит, и это проверяется,
 что с обширной группой данных, нейронных сетей не нуждаются в предварительной подготовки и отказов падения ставки Значительно.

 В 2012 г. в некоторых задачах исследования обеспечили алгоритмы идентификации
 искусственных узоров с производительностью человека.
 И алгоритм Google идентифицирует кошек.

 В 2015, Facebook использует глубокое обучение, 
 чтобы автоматически пометить и распознать пользователей в фотографиях. 
 Алгоритмы выполняют задачи распознавания лиц с помощью глубоких сетей.
 В 2017 году было крупномасштабное внедрение глубокого обученияв различных
 бизнес-приложениях и мобильных устройствах, а также прогресс в исследованиях.

 Обязательство глубокого обучения заключается в том, 
 чтобы продемонстрировать, что довольно обширный набор данных,
 быстрых процессоров и довольно сложный алгоритм позволяет компьютерам выполнять такие задачи,
 как распознавание образов и голоса, среди прочих возможностей. 

 Исследование нейронных сетей приобрело известность благодаря перспективным атрибутам, 
 представленным моделями нейронной сети, созданными благодаря недавним технологическим нововведениям,
 которые позволяют разрабатывать дерзкие нейронные структуры параллельно с оборудованием,
 достигая удовлетворительных характеристик этих систем,
 с превосходной производительностью к обычным системам, 
 Эволюция нейронных сетей "--- это глубокое обучение.